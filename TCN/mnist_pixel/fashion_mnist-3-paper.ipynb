{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, os\n",
    "sys.path.append('/home/A00512318/TCN')\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from TCN.mnist_pixel.utils import data_generator\n",
    "from TCN.mnist_pixel.model import TCN\n",
    "import numpy as np\n",
    "import argparse\n",
    "\n",
    "# set default values for model\n",
    "batch_size = 64\n",
    "cuda = True\n",
    "dropout = 0.15803481115567097\n",
    "clip = -1\n",
    "epochs = 10\n",
    "kernel_size = 6\n",
    "levels = 8\n",
    "log_interval = 100\n",
    "lr = 0.0002099003405580982\n",
    "optimm = 'Adam'\n",
    "nhid = 26\n",
    "seed = 1111\n",
    "permutee = False\n",
    "root = '../data/fashion_mnist'\n",
    "save_filename = './checkpoints/fashionmnist/fashionmnist_real_lookbest_3.pt'\n",
    "input_channels = 1\n",
    "n_classes = 10\n",
    "seq_length = int(784 / input_channels)\n",
    "steps = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import datasets, transforms\n",
    "\n",
    "def data_generator(root, batch_size):\n",
    "    train_set = datasets.FashionMNIST(root=root, train=True, download=True,\n",
    "                               transform=transforms.Compose([\n",
    "                                   transforms.ToTensor(),\n",
    "                                   transforms.Normalize((0.1307,), (0.3081,))\n",
    "                               ]))\n",
    "    test_set = datasets.FashionMNIST(root=root, train=False, download=True,\n",
    "                              transform=transforms.Compose([\n",
    "                                  transforms.ToTensor(),\n",
    "                                  transforms.Normalize((0.1307,), (0.3081,))\n",
    "                              ]))\n",
    "\n",
    "    train_loader = torch.utils.data.DataLoader(train_set, batch_size=batch_size)\n",
    "    test_loader = torch.utils.data.DataLoader(test_set, batch_size=batch_size)\n",
    "    return train_loader, test_loader\n",
    "\n",
    "train_loader, test_loader = data_generator(root, batch_size)\n",
    "\n",
    "classes = ('T-shirt/Top', 'Trouser', 'Pullover', 'Dress', 'Coat', 'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle boot')\n",
    "# print(classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trainTCN(ep):\n",
    "    global steps\n",
    "    train_loss = 0\n",
    "    model.train()\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        if cuda: \n",
    "            data, target = data.to(device), target.to(device)\n",
    "        data = data.view(-1, input_channels, seq_length)\n",
    "        if permutee:\n",
    "            data = data[:, :, permute]\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        loss = F.nll_loss(output, target)\n",
    "        loss.backward()\n",
    "        if clip > 0:\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), clip)\n",
    "        optimizer.step()\n",
    "        train_loss += loss.item()\n",
    "        steps += seq_length\n",
    "        if batch_idx > 0 and batch_idx % log_interval == 0:\n",
    "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}\\tSteps: {}'.format(\n",
    "                ep, batch_idx * batch_size, len(train_loader.dataset),\n",
    "                100. * batch_idx / len(train_loader), train_loss/log_interval, steps))\n",
    "            train_losses_[ep-1].append((train_loss/log_interval, steps))\n",
    "            train_loss = 0  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "def testTCN():\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    correct_class = list(0. for i in range(10))\n",
    "    correct_total = list(0. for i in range(10))\n",
    "    tot = 0\n",
    "    confusion_matrix = [[] for i in range(len(classes))]\n",
    "    with torch.no_grad():\n",
    "        for data, target in test_loader:\n",
    "            if cuda:\n",
    "                data, target = data.to(device), target.to(device)\n",
    "            data = data.view(-1, input_channels, seq_length)\n",
    "            if permutee:\n",
    "                data = data[:, :, permute]\n",
    "            output = model(data)\n",
    "            test_loss += F.nll_loss(output, target, size_average=False).item()\n",
    "            _, pred = torch.max(output, 1)\n",
    "            correct += pred.eq(target.data.view_as(pred)).cpu().sum()\n",
    "#             print(len(target.data.view_as(pred)))\n",
    "            c = (pred == target).squeeze()\n",
    "            tot += 1\n",
    "#             if tot != 313:\n",
    "#             for i in range(len(test_loader.dataset) // batch_size):\n",
    "# #                     print(pred[i], target.data.view_as(pred)[i])\n",
    "#                 print(i)\n",
    "#                 label = pred[i]\n",
    "#                 if (pred[i] == target.data.view_as(pred)[i]):\n",
    "#                     correct_class[label] += c[i].item()\n",
    "#                 correct_total[label] += 1\n",
    "                    \n",
    "                \n",
    "#     print(tot)\n",
    "#     for i in range(10):\n",
    "#         print('Accuracy of %5s : %2d %%' % (\n",
    "#             classes[i], 100 * correct_class[i] / correct_total[i]))\n",
    "\n",
    "    test_loss /= len(test_loader.dataset)\n",
    "#     print(correct.item())\n",
    "    accuracies_.append(correct.item() / 10000.)\n",
    "    \n",
    "    print('\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
    "        test_loss, correct, len(test_loader.dataset),\n",
    "        100. * correct / len(test_loader.dataset)))\n",
    "    return test_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 [6400/60000 (11%)]\tLoss: 2.333956\tSteps: 79184\n",
      "Train Epoch: 1 [12800/60000 (21%)]\tLoss: 1.611906\tSteps: 157584\n",
      "Train Epoch: 1 [19200/60000 (32%)]\tLoss: 1.121247\tSteps: 235984\n",
      "Train Epoch: 1 [25600/60000 (43%)]\tLoss: 0.921388\tSteps: 314384\n",
      "Train Epoch: 1 [32000/60000 (53%)]\tLoss: 0.817358\tSteps: 392784\n",
      "Train Epoch: 1 [38400/60000 (64%)]\tLoss: 0.765209\tSteps: 471184\n",
      "Train Epoch: 1 [44800/60000 (75%)]\tLoss: 0.724044\tSteps: 549584\n",
      "Train Epoch: 1 [51200/60000 (85%)]\tLoss: 0.699181\tSteps: 627984\n",
      "Train Epoch: 1 [57600/60000 (96%)]\tLoss: 0.668623\tSteps: 706384\n",
      "\n",
      "Test set: Average loss: 0.6760, Accuracy: 7591/10000 (75%)\n",
      "\n",
      "Saved as ./checkpoints/fashionmnist/fashionmnist_real_lookbest_3.pt\n",
      "Train Epoch: 2 [6400/60000 (11%)]\tLoss: 0.649692\tSteps: 814576\n",
      "Train Epoch: 2 [12800/60000 (21%)]\tLoss: 0.619453\tSteps: 892976\n",
      "Train Epoch: 2 [19200/60000 (32%)]\tLoss: 0.629884\tSteps: 971376\n",
      "Train Epoch: 2 [25600/60000 (43%)]\tLoss: 0.604885\tSteps: 1049776\n",
      "Train Epoch: 2 [32000/60000 (53%)]\tLoss: 0.586356\tSteps: 1128176\n",
      "Train Epoch: 2 [38400/60000 (64%)]\tLoss: 0.577939\tSteps: 1206576\n",
      "Train Epoch: 2 [44800/60000 (75%)]\tLoss: 0.552786\tSteps: 1284976\n",
      "Train Epoch: 2 [51200/60000 (85%)]\tLoss: 0.545543\tSteps: 1363376\n",
      "Train Epoch: 2 [57600/60000 (96%)]\tLoss: 0.548469\tSteps: 1441776\n",
      "\n",
      "Test set: Average loss: 0.5498, Accuracy: 8025/10000 (80%)\n",
      "\n",
      "Saved as ./checkpoints/fashionmnist/fashionmnist_real_lookbest_3.pt\n",
      "Train Epoch: 3 [6400/60000 (11%)]\tLoss: 0.531602\tSteps: 1549968\n",
      "Train Epoch: 3 [12800/60000 (21%)]\tLoss: 0.526601\tSteps: 1628368\n",
      "Train Epoch: 3 [19200/60000 (32%)]\tLoss: 0.535913\tSteps: 1706768\n",
      "Train Epoch: 3 [25600/60000 (43%)]\tLoss: 0.511393\tSteps: 1785168\n",
      "Train Epoch: 3 [32000/60000 (53%)]\tLoss: 0.507973\tSteps: 1863568\n",
      "Train Epoch: 3 [38400/60000 (64%)]\tLoss: 0.502421\tSteps: 1941968\n",
      "Train Epoch: 3 [44800/60000 (75%)]\tLoss: 0.482822\tSteps: 2020368\n",
      "Train Epoch: 3 [51200/60000 (85%)]\tLoss: 0.498429\tSteps: 2098768\n",
      "Train Epoch: 3 [57600/60000 (96%)]\tLoss: 0.490081\tSteps: 2177168\n",
      "\n",
      "Test set: Average loss: 0.4973, Accuracy: 8212/10000 (82%)\n",
      "\n",
      "Saved as ./checkpoints/fashionmnist/fashionmnist_real_lookbest_3.pt\n",
      "Train Epoch: 4 [6400/60000 (11%)]\tLoss: 0.469315\tSteps: 2285360\n",
      "Train Epoch: 4 [12800/60000 (21%)]\tLoss: 0.471646\tSteps: 2363760\n",
      "Train Epoch: 4 [19200/60000 (32%)]\tLoss: 0.489724\tSteps: 2442160\n",
      "Train Epoch: 4 [25600/60000 (43%)]\tLoss: 0.463330\tSteps: 2520560\n",
      "Train Epoch: 4 [32000/60000 (53%)]\tLoss: 0.453285\tSteps: 2598960\n",
      "Train Epoch: 4 [38400/60000 (64%)]\tLoss: 0.459291\tSteps: 2677360\n",
      "Train Epoch: 4 [44800/60000 (75%)]\tLoss: 0.446860\tSteps: 2755760\n",
      "Train Epoch: 4 [51200/60000 (85%)]\tLoss: 0.451657\tSteps: 2834160\n",
      "Train Epoch: 4 [57600/60000 (96%)]\tLoss: 0.449905\tSteps: 2912560\n",
      "\n",
      "Test set: Average loss: 0.4599, Accuracy: 8318/10000 (83%)\n",
      "\n",
      "Saved as ./checkpoints/fashionmnist/fashionmnist_real_lookbest_3.pt\n",
      "Train Epoch: 5 [6400/60000 (11%)]\tLoss: 0.441410\tSteps: 3020752\n",
      "Train Epoch: 5 [12800/60000 (21%)]\tLoss: 0.437690\tSteps: 3099152\n",
      "Train Epoch: 5 [19200/60000 (32%)]\tLoss: 0.462874\tSteps: 3177552\n",
      "Train Epoch: 5 [25600/60000 (43%)]\tLoss: 0.438549\tSteps: 3255952\n",
      "Train Epoch: 5 [32000/60000 (53%)]\tLoss: 0.435882\tSteps: 3334352\n",
      "Train Epoch: 5 [38400/60000 (64%)]\tLoss: 0.418801\tSteps: 3412752\n",
      "Train Epoch: 5 [44800/60000 (75%)]\tLoss: 0.422694\tSteps: 3491152\n",
      "Train Epoch: 5 [51200/60000 (85%)]\tLoss: 0.424957\tSteps: 3569552\n",
      "Train Epoch: 5 [57600/60000 (96%)]\tLoss: 0.429725\tSteps: 3647952\n",
      "\n",
      "Test set: Average loss: 0.4422, Accuracy: 8394/10000 (83%)\n",
      "\n",
      "Saving checkpoint for model.....\n",
      "Saved as ./checkpoints/fashionmnist/fashionmnist_real_lookbest_3.pt\n",
      "Train Epoch: 6 [6400/60000 (11%)]\tLoss: 0.408498\tSteps: 3756144\n",
      "Train Epoch: 6 [12800/60000 (21%)]\tLoss: 0.418410\tSteps: 3834544\n",
      "Train Epoch: 6 [19200/60000 (32%)]\tLoss: 0.428877\tSteps: 3912944\n",
      "Train Epoch: 6 [25600/60000 (43%)]\tLoss: 0.407575\tSteps: 3991344\n",
      "Train Epoch: 6 [32000/60000 (53%)]\tLoss: 0.406226\tSteps: 4069744\n",
      "Train Epoch: 6 [38400/60000 (64%)]\tLoss: 0.412689\tSteps: 4148144\n",
      "Train Epoch: 6 [44800/60000 (75%)]\tLoss: 0.398428\tSteps: 4226544\n",
      "Train Epoch: 6 [51200/60000 (85%)]\tLoss: 0.407801\tSteps: 4304944\n",
      "Train Epoch: 6 [57600/60000 (96%)]\tLoss: 0.408306\tSteps: 4383344\n",
      "\n",
      "Test set: Average loss: 0.4170, Accuracy: 8462/10000 (84%)\n",
      "\n",
      "Saved as ./checkpoints/fashionmnist/fashionmnist_real_lookbest_3.pt\n",
      "Train Epoch: 7 [6400/60000 (11%)]\tLoss: 0.388466\tSteps: 4491536\n",
      "Train Epoch: 7 [12800/60000 (21%)]\tLoss: 0.398906\tSteps: 4569936\n",
      "Train Epoch: 7 [19200/60000 (32%)]\tLoss: 0.412616\tSteps: 4648336\n",
      "Train Epoch: 7 [25600/60000 (43%)]\tLoss: 0.389535\tSteps: 4726736\n",
      "Train Epoch: 7 [32000/60000 (53%)]\tLoss: 0.384494\tSteps: 4805136\n",
      "Train Epoch: 7 [38400/60000 (64%)]\tLoss: 0.390585\tSteps: 4883536\n",
      "Train Epoch: 7 [44800/60000 (75%)]\tLoss: 0.386522\tSteps: 4961936\n",
      "Train Epoch: 7 [51200/60000 (85%)]\tLoss: 0.392920\tSteps: 5040336\n",
      "Train Epoch: 7 [57600/60000 (96%)]\tLoss: 0.394499\tSteps: 5118736\n",
      "\n",
      "Test set: Average loss: 0.4112, Accuracy: 8509/10000 (85%)\n",
      "\n",
      "Saved as ./checkpoints/fashionmnist/fashionmnist_real_lookbest_3.pt\n",
      "Train Epoch: 8 [6400/60000 (11%)]\tLoss: 0.373823\tSteps: 5226928\n",
      "Train Epoch: 8 [12800/60000 (21%)]\tLoss: 0.371077\tSteps: 5305328\n",
      "Train Epoch: 8 [19200/60000 (32%)]\tLoss: 0.398573\tSteps: 5383728\n",
      "Train Epoch: 8 [25600/60000 (43%)]\tLoss: 0.373638\tSteps: 5462128\n",
      "Train Epoch: 8 [32000/60000 (53%)]\tLoss: 0.380265\tSteps: 5540528\n",
      "Train Epoch: 8 [38400/60000 (64%)]\tLoss: 0.383487\tSteps: 5618928\n",
      "Train Epoch: 8 [44800/60000 (75%)]\tLoss: 0.371164\tSteps: 5697328\n",
      "Train Epoch: 8 [51200/60000 (85%)]\tLoss: 0.371095\tSteps: 5775728\n",
      "Train Epoch: 8 [57600/60000 (96%)]\tLoss: 0.387222\tSteps: 5854128\n",
      "\n",
      "Test set: Average loss: 0.3874, Accuracy: 8609/10000 (86%)\n",
      "\n",
      "Saved as ./checkpoints/fashionmnist/fashionmnist_real_lookbest_3.pt\n",
      "Train Epoch: 9 [6400/60000 (11%)]\tLoss: 0.363601\tSteps: 5962320\n",
      "Train Epoch: 9 [12800/60000 (21%)]\tLoss: 0.366210\tSteps: 6040720\n",
      "Train Epoch: 9 [19200/60000 (32%)]\tLoss: 0.383009\tSteps: 6119120\n",
      "Train Epoch: 9 [25600/60000 (43%)]\tLoss: 0.365198\tSteps: 6197520\n",
      "Train Epoch: 9 [32000/60000 (53%)]\tLoss: 0.369803\tSteps: 6275920\n",
      "Train Epoch: 9 [38400/60000 (64%)]\tLoss: 0.367950\tSteps: 6354320\n",
      "Train Epoch: 9 [44800/60000 (75%)]\tLoss: 0.360245\tSteps: 6432720\n",
      "Train Epoch: 9 [51200/60000 (85%)]\tLoss: 0.370257\tSteps: 6511120\n",
      "Train Epoch: 9 [57600/60000 (96%)]\tLoss: 0.377983\tSteps: 6589520\n",
      "\n",
      "Test set: Average loss: 0.3851, Accuracy: 8585/10000 (85%)\n",
      "\n",
      "Saved as ./checkpoints/fashionmnist/fashionmnist_real_lookbest_3.pt\n",
      "Train Epoch: 10 [6400/60000 (11%)]\tLoss: 0.352776\tSteps: 6697712\n",
      "Train Epoch: 10 [12800/60000 (21%)]\tLoss: 0.360206\tSteps: 6776112\n",
      "Train Epoch: 10 [19200/60000 (32%)]\tLoss: 0.376409\tSteps: 6854512\n",
      "Train Epoch: 10 [25600/60000 (43%)]\tLoss: 0.347071\tSteps: 6932912\n",
      "Train Epoch: 10 [32000/60000 (53%)]\tLoss: 0.360111\tSteps: 7011312\n",
      "Train Epoch: 10 [38400/60000 (64%)]\tLoss: 0.353983\tSteps: 7089712\n",
      "Train Epoch: 10 [44800/60000 (75%)]\tLoss: 0.350625\tSteps: 7168112\n",
      "Train Epoch: 10 [51200/60000 (85%)]\tLoss: 0.358151\tSteps: 7246512\n",
      "Train Epoch: 10 [57600/60000 (96%)]\tLoss: 0.364142\tSteps: 7324912\n",
      "\n",
      "Test set: Average loss: 0.3744, Accuracy: 8634/10000 (86%)\n",
      "\n",
      "Saving checkpoint for model.....\n",
      "Saved as ./checkpoints/fashionmnist/fashionmnist_real_lookbest_3.pt\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "permute = torch.Tensor(np.random.permutation(784).astype(np.float64)).long()\n",
    "channel_sizes = [nhid] * levels\n",
    "model = TCN(input_channels, n_classes, channel_sizes, kernel_size=kernel_size, dropout=dropout)\n",
    "\n",
    "model = nn.DataParallel(model)\n",
    "model.to(device)\n",
    "\n",
    "# permute = permute.cuda()\n",
    "permute = permute.to(device)\n",
    "optimizer = getattr(optim, optimm)(model.parameters(), lr=lr)\n",
    "accuracies_ = []\n",
    "train_losses_ = [[] for i in range(0, epochs)]\n",
    "scores = []\n",
    "for epoch in range(1, epochs+1):\n",
    "    trainTCN(epoch)\n",
    "    testTCN()\n",
    "    if epoch % 5 == 0: \n",
    "        print('Saving checkpoint for model.....')\n",
    "        torch.save({\n",
    "            'epoch': epoch,\n",
    "            'model_state_dict': model.module.state_dict(),\n",
    "            'optimizer_state_dict': optimizer.state_dict(),\n",
    "            'train_losses': train_losses_,\n",
    "            'accuracies': accuracies_,\n",
    "            'curr_lr': lr,\n",
    "        }, save_filename)\n",
    "    if epoch % 10 == 0:\n",
    "        lr /= 10\n",
    "        for param_group in optimizer.param_groups:\n",
    "            param_group['lr'] = lr\n",
    "    torch.save(model.module.state_dict(), save_filename)\n",
    "    scores.append({\n",
    "        'accuracies': accuracies_,\n",
    "        'train_losses': train_losses_,\n",
    "    })\n",
    "    print('Saved as %s' % save_filename) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "36400"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loaded_model = None\n",
    "with open(save_filename, 'rb') as f:\n",
    "        loaded_model = torch.load(f)\n",
    "#         print(model)\n",
    "        \n",
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "count_parameters(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_model.to(device)\n",
    "# kernel = loaded_model.module.tcn.network[0].net[0].weight.data.clone()\n",
    "# kernel.shape\n",
    "# kernel\n",
    "# loaded_model.module.tcn.network\n",
    "loaded_model.module.tcn.network[0].net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "plt.figure(figsize=(10,10))\n",
    "for idx, filt  in enumerate(kernel):\n",
    "#     print(filt[0, :])\n",
    "#     print(filt[0, :])\n",
    "#     plt.subplot(4,7, idx + 1)\n",
    "    plt.imshow(filt, cmap=\"gray\")\n",
    "    plt.axis('off')\n",
    "    \n",
    "    \n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Data for plotting\n",
    "t = np.arange(1, 21)\n",
    "# s = 1 + np.sin(2 * np.pi * t)\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.plot(t, accuracy_)\n",
    "\n",
    "ax.set(xlabel='Epoch', ylabel='Accuracy',\n",
    "       title='TCN')\n",
    "ax.grid()\n",
    "\n",
    "fig.savefig(\"test.png\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.to"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
