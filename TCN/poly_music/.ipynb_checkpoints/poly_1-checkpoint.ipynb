{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, os\n",
    "sys.path.append('/home/A00512318/TCN')\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "import torch.optim as optim\n",
    "from TCN.poly_music.model import TCN\n",
    "import numpy as np\n",
    "\n",
    "# set hyperparameters and settings\n",
    "cuda_ = True\n",
    "dropout_ = 0.25\n",
    "clip_ = 0.4\n",
    "epochs_ = 100\n",
    "kernel_size_ = 6\n",
    "levels_ = 4\n",
    "log_interval_ = 100\n",
    "lr_ = 1e-3\n",
    "optim_ = 'Adam'\n",
    "nhid_ = 150\n",
    "input_size_ = 88 # number of keys on a piano\n",
    "seed_ = 1111\n",
    "n_channels_ = [nhid_] * levels_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7f11972a6df0>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Set the random seed manually for reproducibility.\n",
    "torch.manual_seed(seed_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading Muse data...\n"
     ]
    }
   ],
   "source": [
    "from scipy.io import loadmat\n",
    "\n",
    "def data_generator(dataset):\n",
    "    if dataset == \"JSB\":\n",
    "        print('loading JSB data...')\n",
    "        data = loadmat('./mdata/JSB_Chorales.mat')\n",
    "    elif dataset == \"Muse\":\n",
    "        print('loading Muse data...')\n",
    "        data = loadmat('./mdata/MuseData.mat')\n",
    "    elif dataset == \"Nott\":\n",
    "        print('loading Nott data...')\n",
    "        data = loadmat('./mdata/Nottingham.mat')\n",
    "    elif dataset == \"Piano\":\n",
    "        print('loading Piano data...')\n",
    "        data = loadmat('./mdata/Piano_midi.mat')\n",
    "\n",
    "    X_train = data['traindata'][0]\n",
    "    X_valid = data['validdata'][0]\n",
    "    X_test = data['testdata'][0]\n",
    "\n",
    "    for data in [X_train, X_valid, X_test]:\n",
    "        for i in range(len(data)):\n",
    "            data[i] = torch.Tensor(data[i].astype(np.float64))\n",
    "\n",
    "    return X_train, X_valid, X_test\n",
    "\n",
    "X_train_, X_valid_, X_test_ = data_generator(\"Muse\") # tests will be done with the Muse data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataParallel(\n",
       "  (module): TCN(\n",
       "    (tcn): TemporalConvNet(\n",
       "      (network): Sequential(\n",
       "        (0): TemporalBlock(\n",
       "          (conv1): Conv1d(88, 150, kernel_size=(6,), stride=(1,), padding=(5,))\n",
       "          (chomp1): Chomp1d()\n",
       "          (relu1): ReLU()\n",
       "          (dropout1): Dropout(p=0.25)\n",
       "          (conv2): Conv1d(150, 150, kernel_size=(6,), stride=(1,), padding=(5,))\n",
       "          (chomp2): Chomp1d()\n",
       "          (relu2): ReLU()\n",
       "          (dropout2): Dropout(p=0.25)\n",
       "          (net): Sequential(\n",
       "            (0): Conv1d(88, 150, kernel_size=(6,), stride=(1,), padding=(5,))\n",
       "            (1): Chomp1d()\n",
       "            (2): ReLU()\n",
       "            (3): Dropout(p=0.25)\n",
       "            (4): Conv1d(150, 150, kernel_size=(6,), stride=(1,), padding=(5,))\n",
       "            (5): Chomp1d()\n",
       "            (6): ReLU()\n",
       "            (7): Dropout(p=0.25)\n",
       "          )\n",
       "          (downsample): Conv1d(88, 150, kernel_size=(1,), stride=(1,))\n",
       "          (relu): ReLU()\n",
       "        )\n",
       "        (1): TemporalBlock(\n",
       "          (conv1): Conv1d(150, 150, kernel_size=(6,), stride=(1,), padding=(10,), dilation=(2,))\n",
       "          (chomp1): Chomp1d()\n",
       "          (relu1): ReLU()\n",
       "          (dropout1): Dropout(p=0.25)\n",
       "          (conv2): Conv1d(150, 150, kernel_size=(6,), stride=(1,), padding=(10,), dilation=(2,))\n",
       "          (chomp2): Chomp1d()\n",
       "          (relu2): ReLU()\n",
       "          (dropout2): Dropout(p=0.25)\n",
       "          (net): Sequential(\n",
       "            (0): Conv1d(150, 150, kernel_size=(6,), stride=(1,), padding=(10,), dilation=(2,))\n",
       "            (1): Chomp1d()\n",
       "            (2): ReLU()\n",
       "            (3): Dropout(p=0.25)\n",
       "            (4): Conv1d(150, 150, kernel_size=(6,), stride=(1,), padding=(10,), dilation=(2,))\n",
       "            (5): Chomp1d()\n",
       "            (6): ReLU()\n",
       "            (7): Dropout(p=0.25)\n",
       "          )\n",
       "          (relu): ReLU()\n",
       "        )\n",
       "        (2): TemporalBlock(\n",
       "          (conv1): Conv1d(150, 150, kernel_size=(6,), stride=(1,), padding=(20,), dilation=(4,))\n",
       "          (chomp1): Chomp1d()\n",
       "          (relu1): ReLU()\n",
       "          (dropout1): Dropout(p=0.25)\n",
       "          (conv2): Conv1d(150, 150, kernel_size=(6,), stride=(1,), padding=(20,), dilation=(4,))\n",
       "          (chomp2): Chomp1d()\n",
       "          (relu2): ReLU()\n",
       "          (dropout2): Dropout(p=0.25)\n",
       "          (net): Sequential(\n",
       "            (0): Conv1d(150, 150, kernel_size=(6,), stride=(1,), padding=(20,), dilation=(4,))\n",
       "            (1): Chomp1d()\n",
       "            (2): ReLU()\n",
       "            (3): Dropout(p=0.25)\n",
       "            (4): Conv1d(150, 150, kernel_size=(6,), stride=(1,), padding=(20,), dilation=(4,))\n",
       "            (5): Chomp1d()\n",
       "            (6): ReLU()\n",
       "            (7): Dropout(p=0.25)\n",
       "          )\n",
       "          (relu): ReLU()\n",
       "        )\n",
       "        (3): TemporalBlock(\n",
       "          (conv1): Conv1d(150, 150, kernel_size=(6,), stride=(1,), padding=(40,), dilation=(8,))\n",
       "          (chomp1): Chomp1d()\n",
       "          (relu1): ReLU()\n",
       "          (dropout1): Dropout(p=0.25)\n",
       "          (conv2): Conv1d(150, 150, kernel_size=(6,), stride=(1,), padding=(40,), dilation=(8,))\n",
       "          (chomp2): Chomp1d()\n",
       "          (relu2): ReLU()\n",
       "          (dropout2): Dropout(p=0.25)\n",
       "          (net): Sequential(\n",
       "            (0): Conv1d(150, 150, kernel_size=(6,), stride=(1,), padding=(40,), dilation=(8,))\n",
       "            (1): Chomp1d()\n",
       "            (2): ReLU()\n",
       "            (3): Dropout(p=0.25)\n",
       "            (4): Conv1d(150, 150, kernel_size=(6,), stride=(1,), padding=(40,), dilation=(8,))\n",
       "            (5): Chomp1d()\n",
       "            (6): ReLU()\n",
       "            (7): Dropout(p=0.25)\n",
       "          )\n",
       "          (relu): ReLU()\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (linear): Linear(in_features=150, out_features=88, bias=True)\n",
       "    (sig): Sigmoid()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# set up device and model\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "model = TCN(input_size_, input_size_, n_channels_, kernel_size_, dropout_)\n",
    "\n",
    "model = nn.DataParallel(model)\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion_ = nn.CrossEntropyLoss()\n",
    "optimizer_ = getattr(optim, optim_)(model.parameters(), lr=lr_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(ep):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    count = 0\n",
    "    train_idx_list = np.arange(len(X_train_), dtype=\"int32\")\n",
    "    np.random.shuffle(train_idx_list)\n",
    "    for idx in train_idx_list:\n",
    "        data_line = X_train_[idx]\n",
    "        x, y = Variable(data_line[:-1]), Variable(data_line[1:])\n",
    "        if cuda_:\n",
    "            x, y = x.cuda(), y.cuda()\n",
    "        optimizer_.zero_grad()\n",
    "        output = model(x.unsqueeze(0)).squeeze(0)\n",
    "        loss = -torch.trace(torch.matmul(y, torch.log(output).float().t()) +\n",
    "                            torch.matmul((1 - y), torch.log(1 - output).float().t()))\n",
    "        total_loss += loss.data[0]\n",
    "        count += output.size(0)\n",
    "\n",
    "        if clip_ > 0:\n",
    "            torch.nn.utils.clip_grad_norm(model.parameters(), clip_)\n",
    "        loss.backward()\n",
    "        optimizer_.step()\n",
    "        if idx > 0 and idx % log_interval_ == 0:\n",
    "            cur_loss = total_loss / count\n",
    "            print(\"Epoch {:2d} | lr {:.5f} | loss {:.5f}\".format(ep, lr_, cur_loss))\n",
    "            total_loss = 0.0\n",
    "            count = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(X_data):\n",
    "    eval_idx_list = np.arange(len(X_data), dtype=\"int32\")\n",
    "    total_loss = 0.0\n",
    "    count = 0\n",
    "    with torch.no_grad():\n",
    "        for idx in eval_idx_list:\n",
    "            data_line = X_data[idx]\n",
    "            x, y = Variable(data_line[:-1]), Variable(data_line[1:])\n",
    "            if cuda_:\n",
    "                x, y = x.to(device), y.to(device)\n",
    "            output = model(x.unsqueeze(0)).squeeze(0)\n",
    "            loss = -torch.trace(torch.matmul(y, torch.log(output).float().t()) +\n",
    "                                torch.matmul((1-y), torch.log(1-output).float().t()))\n",
    "            total_loss += loss.data[0]\n",
    "            count += output.size(0)\n",
    "    eval_loss = total_loss / count\n",
    "    print(\"Validation/Test loss: {:.5f}\".format(eval_loss))\n",
    "    return eval_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/A00512318/anaconda3/envs/tcn/lib/python3.7/site-packages/ipykernel/__main__.py:16: UserWarning: invalid index of a 0-dim tensor. This will be an error in PyTorch 0.5. Use tensor.item() to convert a 0-dim tensor to a Python number\n",
      "/home/A00512318/anaconda3/envs/tcn/lib/python3.7/site-packages/ipykernel/__main__.py:20: UserWarning: torch.nn.utils.clip_grad_norm is now deprecated in favor of torch.nn.utils.clip_grad_norm_.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  1 | lr 0.00100 | loss 22.36934\n",
      "Epoch  1 | lr 0.00100 | loss 13.88441\n",
      "Epoch  1 | lr 0.00100 | loss 12.11916\n",
      "Epoch  1 | lr 0.00100 | loss 11.29684\n",
      "Epoch  1 | lr 0.00100 | loss 11.25645\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/A00512318/anaconda3/envs/tcn/lib/python3.7/site-packages/ipykernel/__main__.py:14: UserWarning: invalid index of a 0-dim tensor. This will be an error in PyTorch 0.5. Use tensor.item() to convert a 0-dim tensor to a Python number\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation/Test loss: 11.72277\n",
      "Validation/Test loss: 11.35826\n",
      "Saved model!\n",
      "\n",
      "Epoch  2 | lr 0.00100 | loss 11.60540\n",
      "Epoch  2 | lr 0.00100 | loss 12.45594\n",
      "Epoch  2 | lr 0.00100 | loss 10.74039\n",
      "Epoch  2 | lr 0.00100 | loss 11.60404\n",
      "Epoch  2 | lr 0.00100 | loss 10.55903\n",
      "Validation/Test loss: 10.54598\n",
      "Validation/Test loss: 10.19886\n",
      "Saved model!\n",
      "\n",
      "Epoch  3 | lr 0.00100 | loss 9.29319\n",
      "Epoch  3 | lr 0.00100 | loss 10.86254\n",
      "Epoch  3 | lr 0.00100 | loss 9.83790\n",
      "Epoch  3 | lr 0.00100 | loss 9.81317\n",
      "Epoch  3 | lr 0.00100 | loss 10.89503\n",
      "Validation/Test loss: 9.50115\n",
      "Validation/Test loss: 9.24437\n",
      "Saved model!\n",
      "\n",
      "Epoch  4 | lr 0.00100 | loss 9.26685\n",
      "Epoch  4 | lr 0.00100 | loss 9.16061\n",
      "Epoch  4 | lr 0.00100 | loss 8.55834\n",
      "Epoch  4 | lr 0.00100 | loss 8.18479\n",
      "Epoch  4 | lr 0.00100 | loss 8.85402\n",
      "Validation/Test loss: 8.74890\n",
      "Validation/Test loss: 8.59605\n",
      "Saved model!\n",
      "\n",
      "Epoch  5 | lr 0.00100 | loss 8.68818\n",
      "Epoch  5 | lr 0.00100 | loss 8.41967\n",
      "Epoch  5 | lr 0.00100 | loss 8.17593\n",
      "Epoch  5 | lr 0.00100 | loss 8.87318\n",
      "Epoch  5 | lr 0.00100 | loss 9.27467\n",
      "Validation/Test loss: 8.34976\n",
      "Validation/Test loss: 8.25990\n",
      "Saved model!\n",
      "\n",
      "Epoch  6 | lr 0.00100 | loss 8.06735\n",
      "Epoch  6 | lr 0.00100 | loss 8.27185\n",
      "Epoch  6 | lr 0.00100 | loss 8.64527\n",
      "Epoch  6 | lr 0.00100 | loss 8.58701\n",
      "Epoch  6 | lr 0.00100 | loss 7.31604\n",
      "Validation/Test loss: 9.14979\n",
      "Validation/Test loss: 8.98390\n",
      "Epoch  7 | lr 0.00100 | loss 9.01242\n",
      "Epoch  7 | lr 0.00100 | loss 7.95219\n",
      "Epoch  7 | lr 0.00100 | loss 8.31705\n",
      "Epoch  7 | lr 0.00100 | loss 8.12421\n",
      "Epoch  7 | lr 0.00100 | loss 8.09996\n"
     ]
    }
   ],
   "source": [
    "best_vloss = 1e8\n",
    "vloss_list = []\n",
    "model_name = \"poly_music_MUSE.pt\"\n",
    "for ep in range(1, epochs_+1):\n",
    "    train(ep)\n",
    "    vloss = evaluate(X_valid_)\n",
    "    tloss = evaluate(X_test_)\n",
    "    if vloss < best_vloss:\n",
    "        with open(model_name, \"wb\") as f:\n",
    "            torch.save(model, f)\n",
    "            print(\"Saved model!\\n\")\n",
    "        best_vloss = vloss\n",
    "    if ep > 10 and vloss > max(vloss_list[-3:]):\n",
    "        lr_ /= 10\n",
    "        for param_group in optimizer_.param_groups:\n",
    "            param_group['lr'] = lr_\n",
    "\n",
    "    vloss_list.append(vloss)\n",
    "\n",
    "# print('-' * 89)\n",
    "model = torch.load(open(model_name, \"rb\"))\n",
    "tloss = evaluate(X_test_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:tcn]",
   "language": "python",
   "name": "conda-env-tcn-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
